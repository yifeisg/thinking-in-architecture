# 微信朋友圈高性能复杂度分析



## 数据收集

https://www.sohu.com/a/445526442_115565 *2021-01-19*

> 1 月 19 日晚，在微信公开课 Pro 上，微信创始人张小龙披露微信最新数据：每天有 10.9 亿用户打开微信，3.3 亿用户进行了视频通话；**有 7.8 亿用户进入朋友圈，1.2 亿用户发表朋友圈，其中照片 6.7 亿张，短视频 1 亿条**；有 3.6 亿用户读公众号文章，4 亿用户使用小程序。

https://www.phdmedia.com/phd-insight-wechat-infographic/ *2019-03-26*

一天内微信使用量分布图：

![](https://github.com/yifeisg/thinking-in-architecture/blob/main/week02/wechat_usage_during_a_day.jpg)

为了便于计算，我们将上面的折线图粗略转化为以下直方图：

![](https://github.com/yifeisg/thinking-in-architecture/blob/main/week02/wechat_usage_histogram.jpg)

## 业务指标分析

### 看朋友圈

假设 7.8 亿用户平均每人每天进入 3 次朋友圈，则朋友圈平均每天一共有 23.4 亿次访问。

假设朋友圈使用量的走势与图中 APP 使用量的走势一致，则其峰值出现于 8pm - 9pm，在这 1 小时里一共发生了总访问量的大约 8.5%，也就是约 2 亿次访问。

假设特殊时段（如除夕、跨年）朋友圈的访问量峰值是平时均值的 5 倍，则此时每小时约有 10 亿次访问。

假设这些访问量平均分布于这一小时中的每一秒，则折合到每一秒，有约 **28 万次看朋友圈 QPS**。

> 这 28 万 QPS 还不包括照片大图和短视频的加载，仅仅只是计算了进入朋友圈后下滑浏览的次数。并且根据下滑距离的不同，每个人浏览的朋友圈条数也不同，当浏览条数足够多时，一次进入朋友圈可能会触发多次 query（下滑拉取）。为了简化计算，这些复杂情况我们都不予考虑。

### 发朋友圈

发朋友圈的情况与看朋友圈略有不同：

假设 1.2 亿用户每人每天发 1 条朋友圈，则约有 1.2 亿条，但这个数字明显不准确。

因为光是每天的新增短视频就有 1 亿条，一条朋友圈只能发一个短视频，因此这里就有了 1 亿条朋友圈。

一条朋友圈可以配 1 - 9 张照片，取中间值 5 张 / 条计算，则 6.7 亿张照片可以转化为约 1.3 亿条朋友圈。

我们无法知道有多少条只有文字的朋友圈，为了便于计算，我们假设纯文字朋友圈每天一共 0.7 亿条。则合计每天一共有 3 亿条朋友圈。

考虑到发朋友圈有很大一部分是业务相关，这部分体量在特殊时段（如除夕、跨年）会大幅减少，但同时段其他社交内容的体量又会增加，因此这里不做特殊时期峰值 x 5 的处理。但出于资源冗余的安全考虑，我们 x 2 设计来留出余量，即假设发朋友圈的日峰值为 6 亿条。

那么按照之前的直方图分析，假设这 6 亿条朋友圈有 8.5% 是在 8pm - 9pm 这一个小时内发出，则一共有 5100 万次发布，约合每秒 **1.4 万条发朋友圈 TPS** 。

> 我们没有使用 “假设每条朋友圈有多少人浏览” 来计算看朋友圈的 QPS，一是因为每次 query 肯定不止拉取一条朋友圈，二是这些浏览也不一定都发生在一秒内，因此这样的估算有些不准确。

### 点赞评论

假设平均到每条朋友圈下有 5 个点赞和 5 条评论，且假设每秒新增朋友圈数与每秒新增点赞 / 评论数成正相关，则一共是 **7 万个点赞 TPS** 和 **7 万条评论 TPS**。

> 因为数据不足，暂时这么估算一下，实际上点赞数肯定是超过评论数的。

基于以上分析，我们可以得到如下需求：

![](https://github.com/yifeisg/thinking-in-architecture/blob/main/week02/by_case_analysis.jpg)

这个规模远不是单机房或单数据库可以处理的，因此多机房、负载均衡、分库分表等技术手段都是肯定会上的。

发朋友圈这一场景包含了大量短视频和图片的写入、存储，将占用海量的带宽，因此引入 CDN 来降低带宽压力也成为了必然。

此外，朋友圈的一个特性就是冷热数据分明，一周之前的朋友圈就很少有人会去翻看了，因此将一周内的数据保存在缓存中以提高其访问速度也是不错的选择。而更早的数据则可以存入数据库中。

## 架构设计

![](https://github.com/yifeisg/thinking-in-architecture/blob/main/week02/wechat_moments_design.jpg)

### 看朋友圈

考虑到朋友圈 QPS 的量级，整个访问链路设计了三级缓存，以减少图片和视频请求对数据库端的压力：

1. 客户端本地如果有朋友圈内容的缓存，则直接读取，否则执行下一步；
2. 尝试从 CDN L1 回源。如果 L1 有该内容的缓存，则拉取，同时缓存到本地，否则执行下一步；
3. 尝试从 CDN L2 回源。如果 L2 有该内容的缓存，则拉取，同时缓存到 CDN L1 及本地，否则执行下一步；
4. 从数据库读取内容，并依次缓存到 CDN L2，CDN L1 及本地。

考虑到朋友圈是典型的读多写少场景，且对数据的实时性要求并不是特别严苛，对数据库进行了读写分离，使大量并发的读操作不会降低写操作的执行速度。

### 发朋友圈

为了分担数据库端的压力，用户发表的内容会首先缓存到本地，若失败则回滚。

新发布的朋友圈通常都会被好友拉取，因此可以考虑将该条记录依次缓存到 CDN L1、CDN L2 中，并最终在数据库做持久化保存。

为了方便对庞大的并发读请求进行分流，设计数据库时应考虑通过用户注册所在地或其他相关信息进行分库分表，使写操作可以就近写入数据库机房。

以上同样适用于发布点赞和评论。

### 点赞评论

看朋友圈是典型的 pull 模式，而收到对自己发布内容的新增点赞和评论的提醒，则是典型的 push 模式。因此考虑使用消息队列集群来实现类似提醒的发布。

当用户与 MQ 服务器保持长连接（即打开微信时），新增点赞 / 评论将直接弹出提醒；若用户此时未登陆微信，则消息被保存在 broker 中，下次登陆时进行批量提醒。

## 拓展阅读

浅析分布式主从架构下数据一致性问题 https://juejin.cn/post/6969229960515059743

CDN是什么？使用CDN有什么优势？ - 阿里巴巴淘系技术的回答 - 知乎 https://www.zhihu.com/question/36514327/answer/1604554133

MySQL · 引擎特性 · Group Replication内核解析 http://mysql.taobao.org/monthly/2017/08/01/

一线大厂都在用的异地多活的 5 种解决方案 https://zhuanlan.zhihu.com/p/339719447
